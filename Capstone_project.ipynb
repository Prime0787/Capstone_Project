{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62418613-7185-43c6-b1a0-90764e755134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries for hyperparameter tuning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cda22-71c2-41e3-ac1a-722e2052b832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e5872-57bc-41fa-b2c8-84bed06d1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for model evaluation and saving\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e48ac5-17d9-4c69-a209-f4d7a62f05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\abdul\\Documents\\Lung Cancer.csv\")  # Load your dataset\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a112385-d44e-47f6-a0c3-cd8dc7407d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303dfbb-0499-486c-9b78-306ac40f20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop known leakage / non-predictive columns\n",
    "drop_cols = [c for c in [\"id\", \"end_treatment_date\"] if c in df.columns]\n",
    "df = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a553e-33ff-4f7c-8d04-d988fe2a71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date-like columns if present\n",
    "for col in [\"diagnosis_date\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Feature engineering from dates (safe: known at diagnosis)\n",
    "if \"diagnosis_date\" in df.columns:\n",
    "    df[\"diagnosis_year\"] = df[\"diagnosis_date\"].dt.year\n",
    "    df[\"diagnosis_month\"] = df[\"diagnosis_date\"].dt.month\n",
    "    # You can drop the raw date to avoid high cardinality\n",
    "    df = df.drop(columns=[\"diagnosis_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b001c1d1-bca0-4d74-8b54-be809f5c7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Target / features\n",
    "# -----------------------------\n",
    "TARGET = \"survived\"  # 1 = survived, 0 = not\n",
    "assert TARGET in df.columns, f\"'{TARGET}' not found in columns: {df.columns.tolist()}\"\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# Identify column types\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2246f-b860-4286-bbef-7f12502c87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) Train/validation split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Class imbalance handling: scale_pos_weight = (neg/pos) computed on training set\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "scale_pos_weight = (neg / max(pos, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870499d-7995-4ad9-aef6-6a1dbfbba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Preprocess + Model pipeline\n",
    "# -----------------------------\n",
    "numeric_pre = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_pre = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pre, numeric_cols),\n",
    "        (\"cat\", categorical_pre, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"xgb\", model)])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Train\n",
    "# -----------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Evaluate\n",
    "# -----------------------------\n",
    "pred = pipe.predict(X_test)\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, pred), 4))\n",
    "print(\"Precision:\", round(precision_score(y_test, pred), 4))\n",
    "print(\"Recall:\", round(recall_score(y_test, pred), 4))\n",
    "print(\"F1:\", round(f1_score(y_test, pred), 4))\n",
    "print(\"ROC AUC:\", round(roc_auc_score(y_test, proba), 4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6066cf3-68f9-4ec0-961d-9e98daf92de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b871fa0-389b-4589-80d7-33e8d66d3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: 5-fold CV ROC AUC on the training split\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipe, X_train, y_train, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
    "print(f\"\\nCV ROC AUC: mean={cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Curves\n",
    "# -----------------------------\n",
    "RocCurveDisplay.from_predictions(y_test, proba)\n",
    "plt.title(\"XGBoost ROC Curve\")\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
    "plt.title(\"XGBoost Precision–Recall Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b89dcf-aaa9-4d8e-85ea-9afd8f8bfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 8) Feature importance (global)\n",
    "# -----------------------------\n",
    "# Get feature names after preprocessing for readability\n",
    "oh = pipe.named_steps[\"prep\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_names = []\n",
    "if categorical_cols:\n",
    "    cat_names = oh.get_feature_names_out(categorical_cols).tolist()\n",
    "\n",
    "feature_names = numeric_cols + cat_names\n",
    "\n",
    "# Extract XGBoost feature importances aligned to the transformed matrix\n",
    "importances = pipe.named_steps[\"xgb\"].feature_importances_\n",
    "imp_df = (pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "            .sort_values(\"importance\", ascending=False)\n",
    "            .head(25))\n",
    "print(\"\\nTop 25 features by gain:\")\n",
    "print(imp_df)\n",
    "\n",
    "# Quick bar plot of top features\n",
    "plt.figure(figsize=(8, 6))\n",
    "imp_df[::-1].plot(kind=\"barh\", x=\"feature\", y=\"importance\", legend=False)\n",
    "plt.title(\"Top features (XGBoost)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1ad08-0a42-48fb-956a-f50c09e33f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7f860-b5ed-425b-85c5-1e01695f3d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
